{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 1. Get dynamic pipeline parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "keyvaultlsname = 'Ls_KeyVault_01'\n",
        "db_user_key='synapseSQLPoolAdminUsername'\n",
        "db_pwd_key='synapseSQLPoolAdminPassword'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 2. Get username password from keyvault"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "workspace_name=mssparkutils.env.getWorkspaceName()\n",
        "print(workspace_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 3. Get username password from keyvault"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Make sure user has been created through create_db_user.sql before reading the data\n",
        "sc = SparkSession.builder.getOrCreate()\n",
        "token_library = sc._jvm.com.microsoft.azure.synapse.tokenlibrary.TokenLibrary\n",
        "username = token_library.getSecretWithLS(keyvaultlsname, db_user_key)\n",
        "password = token_library.getSecretWithLS(keyvaultlsname, db_pwd_key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 4. Get Data from external Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Make sure the databse \"external_db\" has been created by running the SQL Script create_external_table\n",
        "\n",
        "# Read Top 5 lines from the parking data\n",
        "hostname = f\"{workspace_name}-ondemand.sql.<YOUR_SYNAPSE_SQL_ENDPOINT>\"\n",
        "print(hostname)\n",
        "port = 1433\n",
        "database = \"external_db\" # TODO Run create_external_table.sql Script in Synapse\n",
        "jdbcUrl = f\"jdbc:sqlserver://{hostname}:{port};database={database}\"\n",
        "dbtable = \"dbo.parking_bay_view\"\n",
        "\n",
        "#Parking Data\n",
        "parking_data = spark.read \\\n",
        "    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
        "    .option(\"url\", jdbcUrl) \\\n",
        "    .option(\"dbtable\", dbtable) \\\n",
        "    .option(\"user\", username) \\\n",
        "    .option(\"password\", password) \\\n",
        "    .load()\n",
        "print(parking_data.count())\n",
        "parking_data.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Read Top 5 lines from the sensor data\n",
        "dbtable = \"sensor_view\"\n",
        "sensor_data = spark.read \\\n",
        "    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
        "    .option(\"url\", jdbcUrl) \\\n",
        "    .option(\"dbtable\", dbtable) \\\n",
        "    .option(\"user\", username) \\\n",
        "    .option(\"password\", password) \\\n",
        "    .load()\n",
        "print(sensor_data.count())\n",
        "sensor_data.show(5)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Python 3.11.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
