{
	"name": "04_silver_to_gold_lab",
	"properties": {
		"folder": {
			"name": "Delta/pipelines"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "db662449-b907-4e72-9724-76dff9da79a0"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"\n",
					"%md-sandbox\n",
					"\n",
					"<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
					"  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
					"</div>"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Silver to Gold Step"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Notebook Objective\n",
					"\n",
					"In this notebook you:\n",
					"1. Harden the Silver to Gold step we wrote in the previous notebook using the composable functions in the operations file."
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Step Configuration"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%run ./includes/configuration"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Import Operation Functions"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%run ./includes/main/python/operations"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Start Streams\n",
					"\n",
					"Before we add new streams, let's start the streams we have previously engineered.\n",
					"\n",
					"We will start two named streams:\n",
					"\n",
					"- `write_raw_to_bronze`\n",
					"- `write_bronze_to_silver`"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Current Delta Architecture\n",
					"\n",
					"Next, we demonstrate everything we have built up to this point in our\n",
					"Delta Architecture.\n",
					"\n",
					"Again, we do so with composable functions included in the\n",
					"file `includes/main/python/operations`."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"rawDF = read_stream_raw(spark, rawPath)\n",
					"transformedRawDF = transform_raw(rawDF)\n",
					"rawToBronzeWriter = create_stream_writer(\n",
					"    dataframe=transformedRawDF,\n",
					"    checkpoint=bronzeCheckpoint,\n",
					"    name=\"write_raw_to_bronze\",\n",
					"    partition_column=\"p_ingestdate\",\n",
					")\n",
					"rawToBronzeWriter.start(bronzePath)\n",
					"\n",
					"bronzeDF = read_stream_delta(spark, bronzePath)\n",
					"transformedBronzeDF = transform_bronze(bronzeDF)\n",
					"bronzeToSilverWriter = create_stream_writer(\n",
					"    dataframe=transformedBronzeDF,\n",
					"    checkpoint=silverCheckpoint,\n",
					"    name=\"write_bronze_to_silver\",\n",
					"    partition_column=\"p_eventdate\",\n",
					")\n",
					"bronzeToSilverWriter.start(silverPath)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"**Exercise:** Harden the Silver to Gold step that we created in the previous notebook.\n",
					"\n",
					"Now that you have seen the pattern, fill out the following code block to complete this step.\n",
					"\n",
					"üíÅüèª‚Äç‚ôÄÔ∏èRemember to use `mode=\"complete\"` with streaming aggregate tables."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# ANSWER\n",
					"\n",
					"tableName = \"/aggregate_heartrate\"\n",
					"tableCheckpoint = goldCheckpoint + tableName\n",
					"tablePath = goldPath + tableName\n",
					"\n",
					"silverDF = read_stream_delta(spark, silverPath)\n",
					"transformedSilverDF = transform_silver_mean_agg(silverDF)\n",
					"silverToGoldAggWriter = create_stream_writer(\n",
					"    dataframe=transformedSilverDF,\n",
					"    checkpoint=tableCheckpoint,\n",
					"    name=\"write_silver_to_gold\",\n",
					"    mode=\"complete\",\n",
					")\n",
					"silverToGoldAggWriter.start(tablePath)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## **Exercise:** Show all running streams"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# ANSWER\n",
					"\n",
					"for stream in spark.streams.active:\n",
					"    print(stream.name)"
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Stop All Streams\n",
					"\n",
					"In the next notebook, we will take a look at schema enforcement and evolution with Delta Lake.\n",
					"\n",
					"Before we do so, let's shut down all streams in this notebook."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"stop_all_streams()\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"%md-sandbox\n",
					"&copy; 2020 Databricks, Inc. All rights reserved.<br/>\n",
					"Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
					"<br/>\n",
					"<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"
				],
				"execution_count": null
			}
		]
	}
}